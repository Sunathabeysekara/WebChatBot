{"cells":[{"cell_type":"markdown","metadata":{"id":"2I9fnloMOm55"},"source":["chat bot to read from blogs and sites to retrival information by user query by user using NLP,AI, and pinecorn\n","\n","selenium to extract content data\n","deeplake to store\n","pinecone to get result as nlp"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":23805,"status":"ok","timestamp":1740072489994,"user":{"displayName":"sandeepa sunath","userId":"12472799881445032822"},"user_tz":-330},"id":"Q4QAFkbIO3XE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"22027d6f-7904-47f6-b13b-4feda21fe6aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.4/421.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q deeplake pinecone selenium"]},{"cell_type":"markdown","metadata":{"id":"jEfskWCVH8H4"},"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gOG7SgdTH90j","executionInfo":{"status":"ok","timestamp":1740072538184,"user_tz":-330,"elapsed":48187,"user":{"displayName":"sandeepa sunath","userId":"12472799881445032822"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e95c6b44-1bb2-4753-91c5-e79e280ab98f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#configuring selenium to retrive information from the site\n","from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.chrome.options import Options\n","from google.colab import drive\n","import json\n","drive.mount('/content/drive')\n","\n","# Set up Chrome options for headless mode and run in google chrome\n","options = webdriver.ChromeOptions()\n","options.add_argument('--headless')  # Run Chrome in (headless mode) background without GUI\n","options.add_argument('--no-sandbox')  # Required for Colab\n","#options.add_argument('--disable-dev-shm-usage')  # Overcome limited resource problems\n","\n","# Create the driver object to chrome\n","driver = webdriver.Chrome(options=options)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7242,"status":"ok","timestamp":1740072548415,"user":{"displayName":"sandeepa sunath","userId":"12472799881445032822"},"user_tz":-330},"id":"SSyDMQCaSlmw","outputId":"58787263-6de4-4943-926d-a77a636faa43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the URL: https://builtin.com/data-science/time-series-python\n","A Guide to Time Series Analysis in Python | Built In\n"]}],"source":["#to get the web site URL to\n","url = input(\"Enter the URL: \")\n","\n","# Open the website\n","driver.get(url)\n","\n","# Print the title of the webpage to verify obtained the link correctly\n","print(driver.title)\n","#https://builtin.com/artificial-intelligence"]},{"cell_type":"markdown","metadata":{"id":"HFdo9LYsSi5r"},"source":["returned the topic correcly url linked correcly"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5456,"status":"ok","timestamp":1740072557873,"user":{"displayName":"sandeepa sunath","userId":"12472799881445032822"},"user_tz":-330},"id":"bunIRnVR1h4v","outputId":"ced9c21c-0bf8-4ea1-f431-3b24e8cae2a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Paragraphs:\n","Time series analysis is a common task for data scientists. This guide will introduce you to its key concepts in Python.\n","In their operations, organizations commonly use time series data, which refers to any information collected over a regular interval of time. Analyzing time series data yields insights like trends, seasonal patterns and forecasts into future events that can help generate profits. For example, by understanding the seasonal trends in demand for retail products, companies can plan promotions to maximize sales throughout the year.\n","Time series data, which means any information collected over a regular interval of time, is frequently used in business operations to predict trends or make forecasts. Examples include daily stock prices, energy consumption rates, social media engagement metrics and retail demand, among others.\n"," \n","When analyzing time series data, you first need to check for stationarity and autocorrelation. Stationarity is a way to measure if the data has structural patterns like seasonal trends. Autocorrelation occurs when future values in a time series linearly depend on past values. You need to check for both of these in time series data because they’re assumptions that are made by many widely used methods in time series analysis. For example, the autoregressive integrated moving average (ARIMA) method for forecasting time series assumes stationarity. Further, linear regression for time series forecasting assumes that the data has no autocorrelation. Before conducting these processes, then, you need to know if the data is viable for the analysis.\n","During a time series analysis in Python, you also need to perform trend decomposition and forecast future values. Decomposition allows you to visualize trends in your data, which is a great way to clearly explain their behavior. Finally, forecasting allows you to anticipate future events that can aid in decision making. You can use many different techniques for time series forecasting, but here, we will discuss the autoregressive integrated moving average (ARIMA).\n","We will be working with publicly available airline passenger time series data, which can be found here.\n"," \n","To start, let’s import the Pandas library and read the airline passenger data into a data frame:\n","Now, let’s display the first five rows of data using the data frame head() method:\n","\n","We can see that the data contains a column labeled “Month” that contains dates. In that column, the dates are formatted as year–month. We also see that the data starts in the year 1949.\n","The second column is labeled “#Passengers,” and it contains the number of passengers for the year–month. Let’s take a look at the last five records the data using the tail() method:\n","We see from this process that the data ends in 1960.\n","The next thing we will want to do is convert the month column into a datetime object. This will allow it to programmatically pull time values like the year or month for each record. To do this, we use the Pandas to_datetime() method:\n","Note that this process automatically inserts the first day of each month, which is basically a dummy value since we have no daily passenger data.\n","The next thing we can do is convert the month column to an index. This will allow us to more easily work with some of the packages we will be covering later:\n","Next, let’s generate a time series plot using Seaborn and Matplotlib. This will allow us to visualize the time series data. First, let’s import Matplotlib and Seaborn:\n","Next, let’s generate a line plot using Seaborn:\n","And label the y-axis with Matplotlib:\n","MORE FROM SADRACH PIERRE\n","Need to Perform Financial Data Analysis? Why Python Is Your Best Tool.\n"," \n","Stationarity is a key part of time series analysis. Simply put, stationarity means that the manner in which time series data changes is constant. A stationary time series will not have any trends or seasonal patterns. You should check for stationarity because it not only makes modeling time series easier, but it is an underlying assumption in many time series methods. Specifically, stationarity is assumed for a wide variety of time series forecasting methods including autoregressive moving average (ARMA), ARIMA and Seasonal ARIMA (SARIMA).\n","We will use the Dickey Fuller test to check for stationarity in our data. This test will generate critical values and a p-value, which will allow us to accept or reject the null hypothesis that there is no stationarity. If we reject the null hypothesis, that means we accept the alternative, which states that there is stationarity.\n","These values allow us to test the degree to which present values change with past values. If there is no stationarity in the data set, a change in present values will not cause a significant change in past values.\n","Let’s test for stationarity in our airline passenger data. To start, let’s calculate a seven-month rolling mean:\n","Next, let’s overlay our time series with the seven-month rolling mean and seven-month rolling standard deviation. First, let’s make a Matplotlib plot of our time series:\n","Then the rolling mean:\n","And finally, the rolling standard deviation:\n","Let’s then add a title:\n","And a legend:\n","\n","Next, let’s import the augmented Dickey-Fuller test from the statsmodels package. The documentation for the test can be found here.\n","Next, let’s pass our data frame into the adfuller method. Here, we specify the autolag parameter as “AIC,” which means that the lag is chosen to minimize the information criterion:\n","Next, let’s store our results in a data frame display it:\n","We can see that our data is not stationary from the fact that our p-value is greater than five percent and the test statistic is greater than the critical value. We can also draw these conclusions from inspecting the data, as we see a clear, increasing trend in the number of passengers.\n"," \n","Checking time series data for autocorrelation in Python is another important part of the analytic process. This is a measure of how correlated time series data is at a given point in time with past values, which has huge implications across many industries. For example, if our passenger data has strong autocorrelation, we can assume that high passenger numbers today suggest a strong likelihood that they will be high tomorrow as well.\n","The Pandas data frame has an autocorrelation method that we can use to calculate the autocorrelation in our passenger data. Let’s do this for a one-month lag:\n","Now, let’s try three, six and nine months:\n","We see that, even with a nine-month lag, the data is highly autocorrelated. This is further illustration of the short- and long-term trends in the data.\n"," \n","Trend decomposition is another useful way to visualize the trends in time series data. To proceed, let’s import seasonal_decompose from the statsmodels package:\n","Next, let’s pass our data frame into the seasonal_decompose method and plot the result:\n","From this plot, we can clearly see the increasing trend in number of passengers and the seasonality patterns in the rise and fall in values each year.\n"," \n","Time series forecasting allows us to predict future values in a time series given current and past data. Here, we will use the ARIMA method to forecast the number of passengers, which allows us to forecast future values in terms of a linear combination of past values. We will use the auto_arima package, which will allow us to forgo the time consuming process of hyperparameter tuning.\n","First, let’s split our data for training and testing and visualize the split:\n","The black line corresponds to our training data and the red line corresponds to our test data.\n","Let’s import auto_arima from the pdmarima package, train our model and generate predictions:\n","Below is a truncated sample of the output:\n","Now, let’s display the output of our model:\n","Our predictions are shown in green and the actual values are shown in orange.\n","Finally, let’s calculate root mean squared error (RMSE):\n","MASTER DATA SCIENCE\n","The Ultimate Guide to ROC Curves and AUC\n"," \n","Conducting time series data analysis is a task that almost every data scientist will face in their career. Having a good understanding of the tools and methods for analysis can enable data scientists to uncover trends, anticipate events and consequently inform decision making. Understanding the seasonality patterns through stationarity, autocorrelation and trend decomposition can guide promotion planning throughout the year, which can improve profits for companies. Finally, time series forecasting is a powerful way to anticipate future events in your time series data, which can also significantly impact decision making. These types of analyses are invaluable to any data scientist or data science team that looks to bring value to their company with time series data. The code from this post is available on GitHub.\n"," \n","Time series is a series of data points collected over an interval of time, where each point represents data at a specific timestamp. Python is one programming language used to help conduct time series analysis.\n","Python is one of the best programming languages for time series analysis, as it has extensive libraries, functions and tools available for conducting data analysis.\n","Python is often preferred for time series analysis and forecasting due to its wide range of applications and libraries, though R is also effective when it comes to deep statistical or exploratory analysis of time series data.\n","DataFrames (especially when using pandas) and arrays are some of the best data structures for time series data in Python.\n","\n","\n","\n","\n","Extracted Links:\n","https://builtin.com/\n","https://builtin.com/jobs?search=\n","https://builtin.com/jobs\n","https://employers.builtin.com/membership?utm_medium=BIReferral&utm_source=foremployers\n","https://builtin.com/auth/signup?destination=%2fdata-science%2ftime-series-python\n","https://builtin.com/auth/login?destination=%2fdata-science%2ftime-series-python\n","https://builtin.com/jobs\n","https://builtin.com/companies\n","https://builtin.com/jobs/remote\n","https://builtin.com/tech-topics\n","https://builtin.com/salaries\n","https://builtin.com/awards/us/2025/best-places-to-work\n","https://builtin.com/auth/login?destination=/home/jobs/saved\n","https://builtin.com/tag/artificial-intelligence\n","https://builtin.com/tag/big-data\n","https://builtin.com/tag/data-science\n","https://builtin.com/tag/expert-contributors\n","https://builtin.com/tag/machine-learning\n","https://builtin.com/authors/sadrach-pierre\n","https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fbuiltin.com%2Fdata-science%2Ftime-series-python&mini=true\n","https://builtin.com/authors/brennan-whitfield\n","https://builtin.com/authors/parul-pandey\n","https://builtin.com/data-science/time-series-model\n","https://builtin.com/data-science/data-analytics\n","https://builtin.com/data-science/time-series-forecasting-python\n","https://builtin.com/software-engineering-perspectives/python\n","https://builtin.com/data-science/data-visualization\n","https://www.kaggle.com/chirag19/air-passengers\n","https://builtin.com/data-science/pandas\n","https://builtin.com/data-science/pandas-show-all-columns\n","https://builtin.com/data-science/data-visualization-tutorial\n","https://builtin.com/data-science/financial-data-analysis\n","https://builtin.com/data-science/introduction-segmentation-correlation-time-series-modeling\n","https://builtin.com/data-science/t-test-vs-chi-square\n","https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html\n","https://builtin.com/data-science/msle-vs-mse\n","https://builtin.com/data-science/roc-curves-auc\n","https://builtin.com/learn/careers/data-scientist\n","https://builtin.com/data-science/predictive-analytics-tools\n","https://builtin.com/data-science\n","https://github.com/spierre91/builtiin/blob/main/time_series_analysis.py\n","https://builtin.com/articles/mistral-ai\n","https://builtin.com/artificial-intelligence/model-distillation\n","https://builtin.com/articles/ai-making-saas-bi-tools-obsolete\n","https://builtin.com/jobs\n","https://builtin.com/companies\n","https://builtin.com/tech-topics\n","https://builtin.com/home/jobs/saved\n","https://builtin.com/auth/signup?destination=%2fdata-science%2ftime-series-python\n","https://builtin.com/auth/login?destination=%2fdata-science%2ftime-series-python\n","https://builtin.com/jobs\n","https://builtin.com/companies\n","https://builtin.com/tech-topics\n","https://builtin.com/jobs/remote\n","https://builtin.com/salaries\n","https://builtin.com/awards/us/2025/best-places-to-work\n","https://builtin.com/tech-hubs\n","https://employers.builtin.com/membership?utm_medium=BIReferral&utm_source=foremployers\n","https://builtin.com/\n","https://facebook.com/builtinhq\n","https://twitter.com/builtin\n","https://www.instagram.com/builtin\n","https://www.linkedin.com/company/3763094\n","https://builtin.com/our-story\n","https://employers.builtin.com/careers/\n","https://builtin.com/our-staff\n","https://builtin.com/content-descriptions\n","https://employers.builtin.com/membership?utm_medium=BIReferral&utm_source=foremployers\n","https://builtin.com/expert-contributors\n","https://knowledgebase.builtin.com/s/\n","https://form.jotform.com/223044927257054\n","https://knowledgebase.builtin.com/s/contactsupport\n","https://builtin.com/browse-jobs\n","https://builtin.com/tech-dictionary\n","https://builtin.com/our-sites\n","https://builtin.com/learning-lab-user-agreement\n","https://builtin.com/accessibility-statement\n","https://builtin.com/copyright-policy\n","https://builtin.com/privacy-policy\n","https://builtin.com/community-terms-of-use\n","https://builtin.com/california-do-not-sell-my-information\n","https://builtin.com/ca-notice-collection\n","https://cookiepedia.co.uk/giving-consent-to-cookies\n","https://www.onetrust.com/products/cookie-consent/\n","Data saved successfully to: /content/drive/My Drive/Colab Notebooks//web_data/web_data.json\n"]}],"source":["# Extracting if topic is in the paragraph tags\n","paragraphs = driver.find_elements(By.TAG_NAME, 'p')\n","\n","# Extract and print the text from each paragraph\n","extracted_paragraphs = [paragraph.text for paragraph in paragraphs]\n","print(\"Extracted Paragraphs:\")\n","for paragraph in extracted_paragraphs:\n","    print(paragraph)\n","\n","\n","# Find all <a> tags (links)\n","links = driver.find_elements(By.TAG_NAME, 'a')\n","extracted_links = [link.get_attribute('href') for link in links if link.get_attribute('href')]\n","print(\"Extracted Links:\")\n","for link in extracted_links:\n","    print(link)\n","\n","# Extract the URLs (href) from each link\n","\n","\n","driver.quit()\n","# Organize the extracted data into a dictionary for JSON storage\n","data = {\n","    \"paragraphs\": extracted_paragraphs,\n","    \"links\": extracted_links\n","}\n","drive_file_path = '/content/drive/My Drive/Colab Notebooks//web_data/web_data.json'\n","\n","# Save the extracted data to a JSON file\n","with open(drive_file_path, 'w') as json_file:\n","    json.dump(data, json_file, indent=4)\n","\n","print(f\"Data saved successfully to: {drive_file_path}\")\n"]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","# Step 2: Load the JSON data\n","json_file_path = '/content/drive/My Drive/Colab Notebooks/web_data/web_data.json'\n","with open(json_file_path, 'r') as f:\n","    data = json.load(f)\n","\n","\n","\n","paragraphs = data.get('paragraphs', [])\n","links = data.get('links', [])\n","\n","documents = paragraphs\n","\n","# Step 3: Process the data (Assuming your JSON structure has a 'paragraphs' key)\n","#documents = [entry['paragraph'] for entry in data]  # Adjust based on your JSON structure\n","\n","# Step 4: Use a Language Model\n","qa_pipeline = pipeline(\"question-answering\")\n","\n","# Example question\n","question = \"what is time series analysis?\"\n","\n","# Step 5: Get answers from the documents\n","for document in documents:\n","  if document != '':\n","    result = qa_pipeline(question=question, context=document)\n","    if result['score'] > 0.5:\n","      #set threshold value to get high prob answer\n","      print(f\"Answer: {result['answer']} (Score: {result['score']})\")\n"],"metadata":{"id":"rvQ1l8XfYymM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740073177878,"user_tz":-330,"elapsed":7085,"user":{"displayName":"sandeepa sunath","userId":"12472799881445032822"}},"outputId":"4301b17b-9981-47f6-a4ea-5f834b6c7207"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["Answer: any information collected over a regular interval of time (Score: 0.5237212777137756)\n","Answer: data frame head (Score: 0.6577269434928894)\n","Answer: convert the month column to an index (Score: 0.6391425728797913)\n","Answer: Matplotlib (Score: 0.5531864166259766)\n","Answer: stationarity (Score: 0.7492750287055969)\n","Answer: the rolling standard deviation (Score: 0.5102468729019165)\n","Answer: a legend (Score: 0.7430604100227356)\n","Answer: one-month lag (Score: 0.5140712261199951)\n","Answer: seasonal_decompose method (Score: 0.5112630724906921)\n","Answer: root mean squared error (Score: 0.8712310194969177)\n","Answer: a task that almost every data scientist will face in their career (Score: 0.7778469920158386)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3PTUiKgwBjM4"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMaQn/8f5fCEU9kKqJQaYky"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}